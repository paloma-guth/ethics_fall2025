---
permalink: /casestudy/
title: "When AI Defines Femininity: How Artificial Influencers Shape Gender and Self-Identity"
author_profile: true
---

## Abstract

The rise of AI-generated personas in social media and digital culture has changed the ways in which gender is represented and consumed. Female coded AI systems, from virtual assistants like Siri to hyperreal social media influencers such as Lil Miquela, Imma, Lucy, and Shudu, tend to attract higher engagement and commercial attention, serving as tools for brands to increase profit. Companies deliberately design these personas to meet brand objectives, often perpetuating narrow ideals of femininity while reinforcing pre-existing social and cultural biases. This raises fundamental questions: Can gender be programmed without reproducing stereotypes? And how does this shape audience identity and self-perception, especially among younger users?

Unlike earlier forms of digital ideation of beauty, which relied on Photoshop, filters, and cosmetic enhancements, AI influencers present a level of hyperrealism previously unattainable. Virtual influencers are not simply visual avatars; they are meticulously crafted digital beings with narratives, personalities, and social presence, designed to evoke engagement and emotional attachment. As these figures grow more ubiquitous, understanding their influence on gender norms, body image, and social perception becomes critical to try to mitigate their potential negative effects on younger generations. AI is being used as a tool for the digital colonization of gender, raising the question of whether true gender liberation is possible when the most pervasive cultural images of femininity are meticulously crafted by corporate algorithms and optimized for market appeal.

This case study examines how AI systems encode and perform femininity, highlighting the objectification and commodification of the female form in the digital age. It explores the sociological, psychological, and ethical implications of these digital personas. It focuses on the mechanisms of gender coding in AI, the commercialization of femininity through virtual influencers, the resulting effects on self-image, and contrasts between human-mediated and autonomous AI performances of gender.

**Key words:**

## Coded Femininity

Women have long been represented in digital media as shallow, hypersexualized, or infantilized characters lacking depth, agency, or complexity. In video games, for example, female characters are frequently depicted in revealing clothing even in combat settings, showing that their design prioritizes aesthetic appeal over narrative or functional realism. These portrayals reflect a wider cultural pattern in which femininity is constructed for consumption rather than true representation.

AI systems reproduce these gendered traits by being trained on large datasets that reflect societal patriarchal biases. Large language models, for instance, frequently assign men to high-status professions, such as engineers or doctors, while relegating women to undervalued roles, such as domestic servants or cooks (UNESCO, 2023). Such outputs demonstrate how AI not only reflects but amplifies existing gender hierarchies encoded in training data.

Gender, from a sociological perspective, is not a binary, fixed category; it is fluid, socially constructed system of power used for control, and context-dependent. Yet, AI systems simplify this complexity into discrete categories, often reinforcing Western heteronormative notions of femininity and masculinity.

The design of female AI personas benefits from the underlying capitalist need to profit from every aspect of human life. Through a Marxist feminist lens, these digital figures serve economic interests by transforming femininity into a profitable resource, packaging emotional labor, desirability, and compliance as marketable products. As an example, we have the “helpful” persona of [AI assistant](https://paloma-guth.github.io/ethics_fall2025/casestudy/ai_assistants/) replicating gender roles produced by the division of labor in capitalist societies: women’s work is service-oriented, invisible, and exploited for profit.

The "Silent Plastic Woman" article argues that the concept that digital women are created to be physically perfect, silent, and compliant. It illustrates how coded femininity in AI reproduces expectations of passivity and service, reflecting longstanding societal ideals about how women should behave. This is not only present on academic article, we are currently witnessing a rise in hypermasculine cultural narratives that reduce women to property or status symbols. It is worth questioning whether these submissive digital depictions, such as the default female voice in virtual assistants, have helped reinforce these attitudes by normalizing femininity as obedient, supportive, and easily controlled.

### AI Bias and Algorithmic Stereotypes

Biases are also embedded in generative AI models. Studies using text-to-image models like Stable Diffusion show significant gender and racial biases, including the propagation of racial homogenization, ffor example, depicting Latin American people with a single skin tone and stereotypical traditional clothing despite the region’s vast racial, cultural, and aesthetic diversity. This demonstrates that AI is not a neutral mirror but an active amplifier of existing human biases.

It is important to consider the issues with data, however, Framing bias as “just a data problem” implies that designers, researchers, and institutions are passive recipients of flawed historical information rather than active agents in choosing which data to collect, preserve, and prioritize. Much of the bias embedded in datasets originates not from random gaps but from long-standing structural inequities that rendered certain populations, such as women, racialized groups, and other marginalized identities, unworthy of documentation in the first place. This absence is not accidental; it is a product of historical power relations that shape what counts as knowledge and whose experiences are recorded.

While lost or omitted data cannot be fully recovered, recognizing these omissions is crucial to understanding how bias persists. Models inherit patterns of exclusion because they are built based on data that reflect unequal social visibility. Thus, the issue is not merely that AI systems absorb biased information, but that they operationalize histories of erasure and turn them into automated, scalable outputs.

### Kawaii Culture

The codification of femininity often draws from the aesthetic of "cuteness" (kawaii), particularly visible in Japanese-influenced virtual culture. Virtual entities like Hatsune Miku, embody hyper-feminized, youthful design traits that present them as charming, innocent, and non-threatening. This persona incentivizes viewer engagement, framing the AI not as an equal intelligence, but as a charming, sometimes naive, or non-threatening entity. While commercially successful, this aesthetic narrows the representable spectrum of feminine identity, confining it to traits that are visually pleasing and socially accommodating.

The public reception of these characters reflects the long lived gendered expectations that women perform emotional labor, nurturing, soothing, and supporting others, rather than occupying positions of expertise or authority. The kawaii persona also implies vulnerability, a “cute” character is framed as defenseless and easily dominated, reinforcing the idea that femininity is something to be protected, controlled, or overpowered.

## (After this point text is not edited - Article extracts and unedited paragraphs)

## The Influencer Industry

The hyperreal virtual influencer industry is the epitome of capitalist exploitation applied to identity. Figures like Lil Miquela, Shudu, Imma, and Lucy merge human aesthetics with algorithmic control, offering brands an unprecedented degree of predictability, malleability, and brand safety (_Moustakas et al., 2020_).

Human Influencers' (HIs) persuasiveness rests upon source characteristics (authenticity and credibility). In contrast, Virtual Influencers' persuasiveness is contingent upon their content and technological attributes (Lou et al.). While men are often seen to command larger follower bases, women influencers have an uncanny ability to spur higher levels of engagement, demonstrated by tangible metrics such as reach and engagement (Gilbert et al.). The AI creators are simply leveraging this empirically proven gender advantage in the economy of attention.

VIs achieve engagement not through genuine trust, but through their technological novelty and the entertainment value from its creative storytelling (Choudhry et al.). This confirms the manipulative nature of the relationship; the followers are captivated by the technology of perfection rather than the person (Bowlby, 1982).

Consumers may also utilize machine heuristics (Sundar) to assess VIs’ credibility, perceiving them as more objective and more competent in performing complex and precise tasks than HIs. This creates a powerful, yet false, sense of authority for the brand-aligned femininity they promote.

### Sub-Sections on Key Influencers

- **[Lil Miquela:](https://paloma-guth.github.io/ethics_fall2025/casestudy/lilMiquela/)** Created by the Los Angeles-based startup Brud, Miquela is arguably the most famous VI, blending high fashion, pop music, and social advocacy. Her complex narrative allows her to cultivate a highly curated persona that engages audiences while avoiding the risks inherent in human influencers’ real-life behaviors (_Kondekar et al._, 2025).
    
- **[Imma:](https://paloma-guth.github.io/ethics_fall2025/casestudy/imma/)** A Japanese virtual model known for her blend of reality and digital seamlessness. Her work as a virtual ambassador for brands like Magnum illustrates how VIs participate in global marketing campaigns designed to resonate with aspirational consumers (_Dabiran et al., 2022_).
    
- **[Shudu:](https://paloma-guth.github.io/ethics_fall2025/casestudy/shudu/)** Designed by a British man, Cameron-James Wilson, Shudu is a black AI influencer. This case is highly contested, as Shudu can be seen as a white man’s digital projection and commodification of black womanhood, raising urgent questions about authenticity, representation, and who profits from the digital identities of marginalized groups.
    

### The Male Gaze and Hyper-Feminization

The creation of these personas is often influenced by the **male gaze** and patriarchal ideals, which are encoded into their hyperreal aesthetics. In environments like China's rapidly evolving AI industry, digital entities are often **hyper-feminized** to reflect and reinforce traditional cultural ideals of femininity (_Kefala_, 2025). These design choices raise significant ethical questions about the **objectification and commodification of the female form** in the digital age. By embodying idealized standards of beauty, such as flawless skin, symmetrical features, and youthful appearance, virtual influencers reinforce a singular vision of femininity aligned with commercial objectives, often reflecting globalized beauty norms.

Furthermore, the highly feminine designs of these digital personas attract real-world social harm. A thematic content analysis of comments on Lil Miquela's Instagram revealed that digital misogyny, cyberbullying, and sexism are transferred from human influencers to their virtual counterparts (_Schmithorst_, 2023). This demonstrates that the digital construction of femininity becomes an immediate target for gendered scrutiny and abuse, confirming that the problem lies not just in the _persona_, but in the societal reception of female representations.

The male gaze (Wolf, 1991) is not only visual; it is economic. The VI industry is a direct example of the "growing commodification of women's bodies in the global economy" (Marxist Feminism). The sexualization and hyper-idealization of the virtual female body is part of the capitalist process, turning women’s bodies into objects that can be monetized.

The use of female AI agents amplifies objectification and exacerbates gender power imbalances. This conceptual article is grounded in Technofeminism and an existentialist feminist lens to critique the practice.

## Impact on Self-Image

The hyperreal aesthetics and curated narratives of AI influencers have serious implications on body image, self-esteem, and psychological well-being. Virtual influencers are designed with idealized, youthful, and symmetrical features, often surpassing the limitations of human appearance. Research shows that such portrayals can exacerbate body dissatisfaction and create a sense of “digitized dysmorphia,” wherein individuals measure themselves against unattainable digital standards.

The highly controlled nature of these personas allows them to avoid negative behaviors that human influencers might exhibit, further amplifying their perception of perfection. For female audiences in particular, repeated exposure to these idealized images, amplified by social media algorithms, can intensify feelings of inadequacy and anxiety (_Fardouly & Vartanian, 2016; Meier & Gray, 2013_).

This reflects Baudrillard’s notion of the simulacrum, where the map precedes the territory. The idealised, flawless body and persona of a virtual influencer do not simply imitate a real woman; they construct a new “femininity” that becomes the reference point for both brands and followers. The influencer is less a representation of a woman and more a simulacrum of femininity itself, divorcing the image from any underlying “real” body. This is reinforced by the finding that exposure to non-inclusive AI-generated faces (those that perpetuate stereotypes) can actually increase people's racial and gender biases (_AlDahoul et al._, 2025).

Critics argue that the digitally engineered perfection of virtual influencers perpetuates unrealistic beauty standards. A report by the World Health Organization (2020) indicates that exposure to idealized body images can contribute to body dissatisfaction and eating disorders, particularly among young women.

Among teenagers (ages 13-17), usage of key virtual influencer platforms is high. Girls (ages unspecified, but likely 13-17) reported higher usage than boys on TikTok (73% vs. 60%) and Instagram (69% vs. 55%). This suggests that younger female audiences are disproportionately exposed to the content of these hyper-aesthetic influencers.

VIs "don’t have bad skin days or cellulite or hair that won’t cooperate." They are digital, hyper-optimized models that exist in a state of perpetual idealization, going beyond the limits of Photoshop and human ability. (vox)

The goal of the VI industry is to blur the line between real and fake, achieving what Forbes calls "plausible fakery." This accelerates the feeling of digitized dysmorphia, as the standard being measured against is not a retouched photo, but an engineered, physically impossible simulation of a human being.

## Parasocial Relationships and Emotional Manipulation

Virtual influencers do more than just look perfect; they create a sense of connection with their audience, even though that connection is one-sided. Parasocial theory explains how people can feel emotionally attached to media figures without any real interaction. Followers of virtual influencers often feel like they “know” these personas, engaging with their lives as if they were real people.

This sense of closeness is intentional. These AI personas are designed to have compelling narratives and opinions. For example, Lil Miquela was the subject of a viral marketing stunt when she claimed to have been a victim of sexual assault, using the narrative to signal social awareness and authenticity, despite being a fictional entity (_The PinkNews_, 2019, cited in _Schmithorst_, 2023). The ability of creators to meticulously design and control narratives—including emotional vulnerability or social activism—highlights how technology can blur the line between genuine connection and manipulation.

Virtual personalities are often endowed with carefully crafted backstories and personalities to foster parasocial relationships with followers, leading to a sense of intimacy and loyalty that can be strategically monetized.

Consumers generally respond more favorably when VIs are perceived as advocating for "similar social values" (e.g., social movements, inclusivity). This shows that the social advocacy is a deliberate part of the VI's programming and brand strategy to deepen the parasocial bond, as mentioned in your draft regarding Miquela's use of the #BlackLivesMatter hashtag.

The CASA (Computers Are Social Actors) framework suggests individuals adhere to social conventions and expectations (e.g., gender stereotypes) in human-computer interactions. This means users _mindlessly_ treat the AI persona as a real woman, directing misogyny, objectification, and gendered scrutiny toward them, despite knowing they are artificial.

### The Cute Industry and Algorithmic Presence

This manipulative blurring is amplified in the "cute industry", where the persona’s emotional connection is tied to its algorithmic, non-human nature.

- **[Neuro-sama:](https://paloma-guth.github.io/ethics_fall2025/casestudy/neuroSama/)** As the most popular AI-driven VTuber, Neuro-sama is notable because her personality is fully autonomous and generated by an AI model. Her appeal is often tied to her "cute" mistakes, unexpected (sometimes controversial) dialogue, and her ability to operate **continuously** without the risk of personal scandal associated with a human operator (_Wei et al._, 2025). Her existence highlights a shift from human-mediated digital femininity (like Lil Miquela) to an algorithmic one, where the audience forms a parasocial relationship with the code itself.
    

In these cases, the parasocial relationship is less about relating to a person and more about engaging with an idealized, controlled, and predictable object of desire, which has significant implications for how audiences view authenticity and emotional vulnerability in real-life relationships.

Drawing from studies on the Japanese _kawaii_ aesthetic, the "cute" aesthetic allows consumers to have relationships with their commodities that they might lack with other people in a society pervaded by alienation (Allison, Kinsella). The AI influencer becomes a perfect, controlled object for emotional projection and parasocial engagement—a substitute for complex human relationships.

The aesthetic success of certain AI personas (e.g., Imma, NeuroSama) relies on "cute cues [that] generally those that indicate extreme youth, vulnerability, harmlessness, and need" (Schoepfer, 2008)

## Conclusion

The rise of AI influencers and algorithmically coded personas reveals the complexities of digitally mediated femininity. By encoding societal expectations into visual aesthetics, narratives, and behaviors, AI systems not only reflect existing gender norms but also shape consumer perception and identity. While virtual influencers provide economic and marketing advantages, they also perpetuate unattainable beauty standards, raise ethical concerns regarding authenticity and representation, and, crucially, transfer and amplify existing social biases and online misogyny.

Ultimately, the case of AI femininity demonstrates that gender in digital spaces is simultaneously performative, commodified, and ethically fraught. Future research must continue to investigate how algorithmic gender representations intersect with societal norms, and how these digital creations impact identity, self-perception, and cultural understanding.

What else to include
(stakeholders)
(activity)
(initial questions)
(bibliography)
(ethical frameworks - conclusion)

The lack of clear regulations governing the use of digital personas in marketing raises concerns about accountability and transparency. Brands may circumvent regulations concerning disclosure by creating hyper-realistic avatars that appear human, leading to potential manipulation of consumer perceptions.
Industry-wide ethical guidelines are necessary to address issues like body image and manipulation. Brands should ensure transparency by clearly indicating when an influencer is computer-generated, using hashtags like #VirtualInfluencer

The AI persona "projects the look-and-feel of futurity even as it conserves attitudes and values essential to keeping things just as they are"

## Discussion Questions and Activities

[Go to activities](https://paloma-guth.github.io/ethics_fall2025/casestudy/activity)

## Bibliography

[See references](https://paloma-guth.github.io/ethics_fall2025/casestudy/citations)