---
title: 'INFO Blog 2: Policies for Creative Works'
date: 2025-11-17
permalink: /posts/2025/17/blog-post-10/
tags:
  - Case study
  - creativity
  - art
  - Generative AI
  - Yale Journal
---

**The Imitation Machine**<br>
How AI blurs the line between creation and replication, turning human imagination into raw material for profit.

**Case study:**
[ARTificial: Why Copyright Is Not the Right Policy Tool to Deal with Generative AI](https://yalelawjournal.org/forum/artificial-why-copyright-is-not-the-right-policy-tool-to-deal-with-generative-ai)

Introduction
---
The article *ARTificial: Why Copyright Is Not the Right Policy Tool to Deal with Generative AI* talks about the growing tension between technology, law, and art, questioning whether AI training with unlicensed works counts as fair use or infringement, and if machine-made outputs should qualify for copyright protection.

But beyond the legal questions, what caught my attention is the social side of it and how creativity itself is being redefined. The rise of generative AI feels like a new form of exploitation disguised as progress. What’s being taken isn’t just data, but imagination, the collective result of human expression, scraped and reused by companies claiming innovation. It’s not just about authorship or ownership, but about who gets to shape culture in the future.

Discussion
---
### Training with unlicensed works: fair use or violation?

The case study keeps this as an open legal question, but I honestly don’t think it should even be up for debate. Sure, some argue AI training could be transformative under fair use, but that feels like twisting the law to justify exploitation. Training data isn’t just one piece of art used for reference. it’s gigabytes of work taken from thousands of creators without their consent. That’s not inspiration, that’s extraction.

If a normal person like us can’t use someone else’s work for profit, why should a company be allowed to? The scale makes it worse. One artist referencing another’s style is part of art. But when a company scrapes entire datasets of unlicensed art to make millions, it’s theft dressed up as innovation. Some researchers would call this data colonialism, where human expression is treated as a resource to exploit. The social consequences are real, young artists might feel their labor doesn’t matter, and culture could become homogenized under corporate AI outputs.

### GAI outputs: original or derivative

The case study implies that GAI outputs aren’t automatically derivative, arguing that what models produce isn’t a copy in a legal sense. I do understand that perspective, but I don’t really agree. Machines don’t think, imagine, or interpret; they calculate patterns based on what humans have already made. Every so-called new image or text is a rearrangement of someone's else work that was used as its training set.

Humans are influenced by other work too, but the key difference is agency. When a we create something, we decide what to borrow, what to alter, and what meaning to convey. AI has no judgment, it just reassembles what it sees. So while legally this may be blurry, socially and ethically, it feels quite simple to decide. This also raises concerns about cultural flattening. If AI becomes the dominant creator, will future generations experience homogenized, corporate-filtered culture instead of diverse human perspectives? Again, this isn’t just about ownership, it’s about shaping culture itself.

### Copyright protection for AI outputs and authorship

Again I might not fully agree with this case study as it argues AI work could qualify for copyright if it meets a *modicum of creativity* and introduces the Artistic Turing Test: if humans can’t tell it’s AI-made, maybe it doesn’t matter. For me transparency matters. People should know the source because it affects how we value and interpret creative work. 

If a creation comes from typing a prompt, copyright shouldn’t apply. Ownership comes from effort, time, and creative thought, not automation. U.S. law still requires human authors, which some call outdated, but I see it as an important boundary. Blurring authorship risks erasing artistic labor and could deepen inequalities as those with access to AI can mass produce content, while human creators without it get left behind.

### Distinguishing between autonomous and assisted AI creations

There’s a big difference between using Photoshop AI tolls to flip a drawing and using AI to generate a full piece from scratch. When AI is a tool, something that supports your creative process, then the human artist deserves the copyright. But when AI does all the work, no one should own it, it shouldn't even be allowed to begin with. That kind of output should go to the public domain. For me, giving AI rights or creative ownership is absurd when the models themselves rely entirely on human made material. It’s like giving credit to a mirror for the reflection.

### Impact on the public domain

If AI generated work starts receiving copyright, the public domain might collapse. AI can mass produce thousands of pieces per minute, and each one locks away cultural space. That’s not creativity; that’s noise.

This case study ends by saying this issue goes beyond copyright, and I agree. It’s a social problem. Labor, identity, and cultural control are at stake. Creators lose recognition, work becomes flattened into data, and society is filled with content detached from any human voice and perspective. Maybe this isn’t about fair use at all, maybe it’s about what kind of future we want for creativity itself.

New Discussion Question
---
**Question:** If AI continues to be trained on unlicensed works, does this mark the start of a new kind of cultural inequality, where creative ownership is concentrated in the hands of a few companies?

I wish I had a simpler answer for this, but this is not the case. When companies control both the tools and the data that shape culture, creativity stops being communal and becomes corporate property. This feels like pure alienation, our cultural and emotional expressions turned into products we don’t control. We’re already seeing the consequences: endless similar aesthetics online, echo chambers of AI output. What happens next if this becomes the norm? We will have only noise instead of culture.

Reflection
---
I’m not deeply connected and informed about the professional art world, but this made me think about culture and what future generations will experience. I like browsing Pinterest for art, outfits, or design inspiration, but now even there, AI-generated content dominates (at least they label it).

I recently saw a video about a children’s book created entirely by AI in one day. The illustrations all had the same warm, yellow tones, apparently associated with happiness, and the book felt repetitive and lifeless. This case study also made me think of when I tried generating images with a StyleGAN model. Most of what came out was just noise, not even proper shapes or anything that felt intentional. Thinking about it alongside this case study, I worry that the feedback loop of AI could leave us with nothing but noise, where human creativity is drowned out.

I don’t think art should fall under fair use for AI training, even if it’s for the greater good. Nothing is for the greater good if someone profits from it. We’re already alienated enough, our labor, our ideas, and now our creativity are at risk of being exploited too, if it hasn’t been already.

