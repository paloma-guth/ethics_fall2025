---
title: "Podcast 2: Bot-ched Statistics?"
collection: podcasts
permalink: /podcasts/podcast2
excerpt: "Let’s talk about how large language models (LLMs) share information and how often they can hallucinate."
date: 2025-10-12
audio: ethics_fall2025/files/Fitian_Guth_podcast2.mp3
video: ethics_fall2025/files/Fitian_Guth_video_podcast2.mp4
---

### By Paloma and Omar

In this podcast, we talk about how much large language models (LLMs) actually know about the gig economy and its impact on workers’ rights, and how well they can communicate that information to users. We used ChatGPT to design our prompt, then tested it on DeepSeek and Google Gemini to see how each handled citations, sourcing, and data accuracy.

We discussed how each model performed and whether we noticed any hallucinations (spoiler: there were quite a few from DeepSeek). We also mentioned about why accuracy matters when citing sources, and why relying on LLMs for research can be risky and not advised when tools like Google Scholar are available.

To better follow our discussion, you can view our data outputs [here](https://docs.google.com/document/d/1Bz-lu718gGhg5lFv0B8Pd93_IOsHwLrfZGN40mLOZ-U/edit?usp=sharing).<br>
You can also find the full audio transcript [here](https://drive.google.com/file/d/1H_lAcmBQ4DGdXYh1GrQygNMvtvkMtqXx/view?usp=sharing) if needed.
